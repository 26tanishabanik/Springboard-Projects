{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is...\n",
    "\n",
    "## Machine Learning Models Built:\n",
    "- Ordinary Least Squares\n",
    "- Stochastic Gradient Descent (SGD)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importing and Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "import seaborn as sns \n",
    "\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels\n",
    "\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ML_dataset_filtered.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.set_index('Date').drop(['stid', 'year', 'day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time series energy data displays auto-correlation on a year-to-year scale. We will therefore use temporally contiguous blocks for cross-validation, forcing testing on more temporally distant records, reducing temporal dependence and reducing optimism in error estimates. We are attempting to ensure independence between cross-validation folds. \n",
    "\n",
    "https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.02881\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data have been split into the following groups (years are inclusive):\n",
    "\n",
    "- 1994-1995: Contiguous Fold 1\n",
    "- 1996-1997: Contiguous Fold 2\n",
    "- 1998-1999: Contiguous Fold 3\n",
    "- 2000-2001: Contiguous Fold 4\n",
    "- 2002-2003: Contiguous Fold 5\n",
    "- 2004-2007: Test Data\n",
    "\n",
    "The cross-validation strategy is as follows:\n",
    "- Choose 1 contiguous fold as validation data and use remaining contiguous folds as training data\n",
    "    - Calculate CV score\n",
    "- Perform the above process 5 times, with each of the contiguous folds being the validation data\n",
    "    - Calculate average CV score\n",
    "- Finally, use all 5 contiguous folds as training data and calculate the test data score\n",
    "\n",
    "The models will be evaluated based on the following:\n",
    "- Average CV score\n",
    "- Test data score\n",
    "\n",
    "Hyperparameter Tuning:\n",
    "- If required, hyperparameters can be tuned by calculating the average CV score on the 5 contiguous folds and choosing the optimal parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score(reg, X_train, y_train, score_func=mean_absolute_error):\n",
    "    '''\n",
    "    DOCSTRING\n",
    "    \n",
    "    '''\n",
    "    # In here for now to surpress a warning\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    \n",
    "    result = 0\n",
    "\n",
    "    # Split data into 5 contiguous folds\n",
    "    years = list(range(1994, 2004))\n",
    "    n_fold = 5\n",
    "    fold = 0\n",
    "    \n",
    "    cv_scores = pd.DataFrame()\n",
    "    \n",
    "    for i in list(range(0, len(years), 2)):\n",
    "        \n",
    "        X_tr = X_train[(X_train.index.year != years[i]) & (X_train.index.year != years[i+1])]\n",
    "        y_tr = y_train[(y_train.index.year != years[i]) & (y_train.index.year != years[i+1])].to_frame()\n",
    "        \n",
    "        X_te = X_train.loc[str(years[i]):str(years[i+1])].astype(float)\n",
    "        y_te = y_train.loc[str(years[i]):str(years[i+1])].to_frame().astype(float)\n",
    "    \n",
    "        if reg == 'ols':\n",
    "            \n",
    "            X_tr['energy'] = y_tr.loc[:, 'energy']\n",
    "            \n",
    "            ols_string = 'energy ~ ' + ''.join([i + ' + ' for i in X_tr.columns[:-1]])[:-3]\n",
    "\n",
    "            m = ols(ols_string, X_tr).fit()\n",
    "            mae = score_func(m.predict(X_te), y_te)\n",
    "            result += mae\n",
    "            \n",
    "            temp_df = pd.DataFrame()\n",
    "            temp_df['fold'] = [fold + 1]\n",
    "            temp_df['cv_mae'] = [mae]\n",
    "            cv_scores = cv_scores.append(temp_df)\n",
    "        \n",
    "        else:\n",
    "            reg.fit(X_tr, y_tr)\n",
    "            mae = score_func(reg.predict(X_te), y_te)\n",
    "            result += mae\n",
    "            \n",
    "            temp_df = pd.DataFrame()\n",
    "            temp_df['fold'] = [fold + 1]\n",
    "            temp_df['cv_mae'] = [mae]\n",
    "            cv_scores = cv_scores.append(temp_df)\n",
    "            \n",
    "        fold += 1\n",
    "        \n",
    "        average_cv = result / n_fold\n",
    "        \n",
    "    return average_cv, cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only forecast hour 0 for the purposes of the below analysis\n",
    "df_t0 = df.copy()\n",
    "\n",
    "for col in df_t0.columns:\n",
    "    if str(col)[-6:-1] == 'fhour':\n",
    "        if str(col)[-1] != '0':\n",
    "            del df_t0[col]\n",
    "            \n",
    "# Compute the correlation matrix\n",
    "corr = df_t0.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set column labels\n",
    "column_labels = ['Energy availability', 'Latitude', 'Longitude', 'Elevation','3-Hour accumulated\\nprecipitation', 'Downward long-wave\\nradiative flux average','Downward short-wave\\nradiative flux average', 'Air pressure at\\nmean sea level','Precipitable water', 'Specific humidity','Total cloud cover', 'Total column-integrated\\ncondensate ','Maximum temperature\\nover the past 3 hours', 'Minimum temperature\\nover the past 3 hours','Current temperature\\nat 2m above ground', ' Surface temperature','Surface upward\\nlong-wave radiation', 'Atmosphere upward\\nlong-wave radiation','Surface upward\\nshort-wave radiation', 'Month']\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Draw the heatmap with the mask\n",
    "sns.heatmap(corr, mask=mask, cmap='coolwarm', vmin=-1, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, xticklabels=column_labels, yticklabels=column_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr[corr > 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlwrf_sfcfhour0: 0.279714\n",
    "- pwat_eatmfhour0\n",
    "- spfh_2m_lfhour0\n",
    "- tmax_2m_lfhour0\n",
    "- tmin_2m_lfhour0\n",
    "- tmp_2m_lafhour0\n",
    "- tmp_sfc_lfhour0\n",
    "- ulwrf_sfcfhour0\n",
    "\n",
    "pwat_eatmfhour0: 0.201308\n",
    "- dlwrf_sfcfhour0\n",
    "- spfh_2m_lfhour0 \n",
    "- tmin_2m_lfhour0\n",
    "- tmp_2m_lafhour0\n",
    "- tmp_sfc_lfhour0\n",
    "- ulwrf_sfcfhour0\n",
    "\n",
    "spfh_2m_lfhour0: 0.344125\n",
    "- dlwrf_sfcfhour0\n",
    "- pwat_eatmfhour0\n",
    "- tmax_2m_lfhour0\n",
    "- tmin_2m_lfhour0\n",
    "- tmp_2m_lafhour0\n",
    "- tmp_sfc_lfhour0\n",
    "- ulwrf_sfcfhour0\n",
    "\n",
    "tcdc_eatmfhour0: -0.343932\t(keep)\n",
    "- tcolc_eatfhour0\n",
    "\n",
    "tcolc_eatfhour0: -0.343467\n",
    "- tcdc_eatmfhour0\n",
    "\n",
    "tmax_2m_lfhour0: 0.509588 (keep)\n",
    "- dlwrf_sfcfhour0\n",
    "- spfh_2m_lfhour0\n",
    "\n",
    "tmin_2m_lfhour0: 0.480312\n",
    "- dlwrf_sfcfhour0\n",
    "- pwat_eatmfhour0\n",
    "- spfh_2m_lfhour0\n",
    "- tmax_2m_lfhour0\n",
    "- tmp_2m_lafhour0\n",
    "- tmp_sfc_lfhour0\n",
    "- ulwrf_sfcfhour0\n",
    "\n",
    "tmp_2m_lafhour0: 0.479993\n",
    "- dlwrf_sfcfhour0\n",
    "- pwat_eatmfhour0\n",
    "- spfh_2m_lfhour0\n",
    "- tmax_2m_lfhour0\n",
    "- tmin_2m_lfhour0\n",
    "- tmp_sfc_lfhour0\n",
    "- ulwrf_sfcfhour0\n",
    "\n",
    "tmp_sfc_lfhour0: 0.464945\n",
    "- dlwrf_sfcfhour0\n",
    "- pwat_eatmfhour0\n",
    "- spfh_2m_lfhour0\n",
    "- tmax_2m_lfhour0\n",
    "- tmin_2m_lfhour0\n",
    "- tmp_2m_lafhour0\n",
    "- ulwrf_sfcfhour0\n",
    "\n",
    "ulwrf_sfcfhour0: 0.485866 (keep)\n",
    "- dlwrf_sfcfhour0\n",
    "- pwat_eatmfhour0\n",
    "- spfh_2m_lfhour0\n",
    "- tmax_2m_lfhour0\n",
    "- tmin_2m_lfhour0\n",
    "- tmp_2m_lafhour0\n",
    "- tmp_sfc_lfhour0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,12))\n",
    "plt.scatter(df['spfh_2m_lfhour0'], df['pwat_eatmfhour0'], s=0.1, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: OLS - BASELINE (NO FEATURE SELECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc['1994':'2003'].iloc[:, 1:]\n",
    "y_train = df.energy.loc['1994':'2003']\n",
    "X_test = df.loc['2004':'2007'].iloc[:, 1:]\n",
    "y_test = df.energy.loc['2004':'2007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ols = df.copy()\n",
    "df_ols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_cv, cv_scores = cv_score('ols', X_train, y_train, score_func=mean_absolute_error)\n",
    "print('Average CV MAE: %.0f' % average_cv)\n",
    "cv_scores.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_string = 'energy ~ ' + ''.join([i + ' + ' for i in df_ols.columns[1:]])[:-3]\n",
    "\n",
    "m_ols = ols(ols_string,df_ols).fit()\n",
    "print('MAE: %.0f' % mean_absolute_error(m_ols.predict(X_test), y_test))\n",
    "print(m_ols.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: OLS - FORECAST HOUR0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ols_t0 = df_t0.copy()\n",
    "\n",
    "X_train = df_ols_t0.loc['1994':'2003'].iloc[:, 1:]\n",
    "y_train = df_ols_t0.energy.loc['1994':'2003']\n",
    "X_test = df_ols_t0.loc['2004':'2007'].iloc[:, 1:]\n",
    "y_test = df_ols_t0.energy.loc['2004':'2007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cv, cv_scores = cv_score('ols', X_train, y_train, score_func=mean_absolute_error)\n",
    "print('Average CV MAE: %.0f' % average_cv)\n",
    "cv_scores.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ols_string = 'energy ~ ' + ''.join([i + ' + ' for i in df_ols_t0.columns[1:]])[:-3]\n",
    "\n",
    "m_ols = ols(ols_string,df_ols_t0).fit()\n",
    "print('MAE: %.0f' % mean_absolute_error(m_ols.predict(X_test), y_test))\n",
    "print(m_ols.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: OLS - REDUCED FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ols_fs = df.copy()\n",
    "del df_ols_fs['month']\n",
    "del df_ols_fs['nlat']\n",
    "del df_ols_fs['elon']\n",
    "del df_ols_fs['elev']\n",
    "del df_ols_fs['dlwrf_sfcfhour0']\n",
    "del df_ols_fs['dlwrf_sfcfhour1']\n",
    "del df_ols_fs['dlwrf_sfcfhour2']\n",
    "del df_ols_fs['dlwrf_sfcfhour3']\n",
    "del df_ols_fs['dlwrf_sfcfhour4']\n",
    "del df_ols_fs['pwat_eatmfhour0']\n",
    "del df_ols_fs['pwat_eatmfhour1']\n",
    "del df_ols_fs['pwat_eatmfhour2']\n",
    "del df_ols_fs['pwat_eatmfhour3']\n",
    "del df_ols_fs['pwat_eatmfhour4']\n",
    "del df_ols_fs['spfh_2m_lfhour0']\n",
    "del df_ols_fs['spfh_2m_lfhour1']\n",
    "del df_ols_fs['spfh_2m_lfhour2']\n",
    "del df_ols_fs['spfh_2m_lfhour3']\n",
    "del df_ols_fs['spfh_2m_lfhour4']\n",
    "del df_ols_fs['tcolc_eatfhour0']\n",
    "del df_ols_fs['tcolc_eatfhour1']\n",
    "del df_ols_fs['tcolc_eatfhour2']\n",
    "del df_ols_fs['tcolc_eatfhour3']\n",
    "del df_ols_fs['tcolc_eatfhour4']\n",
    "del df_ols_fs['tmin_2m_lfhour0']\n",
    "del df_ols_fs['tmin_2m_lfhour1']\n",
    "del df_ols_fs['tmin_2m_lfhour2']\n",
    "del df_ols_fs['tmin_2m_lfhour3']\n",
    "del df_ols_fs['tmin_2m_lfhour4']\n",
    "del df_ols_fs['tmp_2m_lafhour0']\n",
    "del df_ols_fs['tmp_2m_lafhour1']\n",
    "del df_ols_fs['tmp_2m_lafhour2']\n",
    "del df_ols_fs['tmp_2m_lafhour3']\n",
    "del df_ols_fs['tmp_2m_lafhour4']\n",
    "del df_ols_fs['tmp_sfc_lfhour0']\n",
    "del df_ols_fs['tmp_sfc_lfhour1']\n",
    "del df_ols_fs['tmp_sfc_lfhour2']\n",
    "del df_ols_fs['tmp_sfc_lfhour3']\n",
    "del df_ols_fs['tmp_sfc_lfhour4']\n",
    "df_ols_fs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_ols_fs.loc['1994':'2003'].iloc[:, 1:]\n",
    "y_train = df_ols_fs.energy.loc['1994':'2003']\n",
    "X_test = df_ols_fs.loc['2004':'2007'].iloc[:, 1:]\n",
    "y_test = df_ols_fs.energy.loc['2004':'2007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cv, cv_scores = cv_score('ols', X_train, y_train, score_func=mean_absolute_error)\n",
    "print('Average CV MAE: %.0f' % average_cv)\n",
    "cv_scores.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ols_string = 'energy ~ ' + ''.join([i + ' + ' for i in df_ols_fs.columns[1:]])[:-3]\n",
    "m_ols_fs = ols(ols_string,df_ols_fs).fit()\n",
    "print('MAE: %.0f' % mean_absolute_error(m_ols_fs.predict(X_test), y_test))\n",
    "print(m_ols_fs.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: SGD - NO FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc['1994':'2003'].iloc[:, 1:]\n",
    "y_train = df.energy.loc['1994':'2003']\n",
    "X_test = df.loc['2004':'2007'].iloc[:, 1:]\n",
    "y_test = df.energy.loc['2004':'2007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "m = SGDRegressor(max_iter=1000, alpha=.00001, tol=.001)\n",
    "reg = make_pipeline(scaler, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cv, cv_scores = cv_score(reg, X_train, y_train, score_func=mean_absolute_error)\n",
    "print('Average CV MAE: %.0f' % average_cv)\n",
    "cv_scores.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "reg = SGDRegressor(max_iter=1000, alpha=.00001, tol=.001)\n",
    "pipeline = make_pipeline(scaler, reg)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('MAE: %.0f' % mean_absolute_error(pipeline.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: GRADIENT BOOSTING REGRESSOR\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc['1994':'2003'].iloc[:, 1:].reset_index()\n",
    "y_train = df.energy.loc['1994':'2003'].reset_index()\n",
    "X_test = df.loc['2004':'2007'].iloc[:, 1:].reset_index()\n",
    "y_test = df.energy.loc['2004':'2007'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbr_gridsearch(X_train, y_train, n_estimators_space, max_features_space, max_depth_space):\n",
    "    \n",
    "    years = list(range(1994, 2004))\n",
    "\n",
    "    train_indices =  [X_train[(X_train.Date.dt.year != years[i]) & (X_train.Date.dt.year != years[i+1])].index for i in list(range(0, len(years), 2))]\n",
    "    test_indices = [y_train[(y_train.Date.dt.year != years[i]) & (y_train.Date.dt.year != years[i+1])].index for i in list(range(0, len(years), 2))]\n",
    "    custom_cv = zip(train_indices, test_indices)\n",
    "    \n",
    "    param_grid = {'n_estimators': n_estimators_space, 'max_features': max_features_space, 'max_depth':max_depth_space}\n",
    "    reg = GradientBoostingRegressor(loss='lad', subsample=0.5)\n",
    "    reg_cv = GridSearchCV(reg, param_grid, cv=custom_cv, verbose=50, n_jobs=2)\n",
    "    \n",
    "    reg_cv.fit(X_train.iloc[:,1:], y_train.iloc[:,1:].values.ravel())\n",
    "    \n",
    "    print(\"Tuned Gradient Boosting Parameters: {}\".format(reg_cv.best_params_)) \n",
    "    print(\"Best score is {}\".format(reg_cv.best_score_))\n",
    "    \n",
    "    return reg_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "n_estimators_space = np.asarray([500, 1000, 1500])\n",
    "max_features_space = np.asarray([6, 10, 14])\n",
    "max_depth_space = np.asarray([3, 4, 5, 6, 7, 8, 9])\n",
    "gbr_reg_cv = gbr_gridsearch(X_train, y_train, n_estimators_space, max_features_space, max_depth_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc['1994':'2003'].iloc[:, 1:]\n",
    "y_train = df.energy.loc['1994':'2003']\n",
    "X_test = df.loc['2004':'2007'].iloc[:, 1:]\n",
    "y_test = df.energy.loc['2004':'2007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor(loss='lad', n_estimators=1000, max_features=10, max_depth=7, subsample=0.5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(reg.predict(X_test), y_test)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitted vs Actual Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test = df.energy.loc['2004':'2007']\n",
    "plt.subplots(figsize=(12, 12))\n",
    "plt.scatter(m_ols.predict(X_test), y_test, s=0.1, alpha=0.5)\n",
    "plt.plot([0,35000000], [0,35000000], '-', c='red')\n",
    "plt.xlabel(\"Fitted Value\")\n",
    "plt.ylabel(\"Actual Energy\")\n",
    "plt.title(\"Relationship between Fitted Values and Actual Energy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitted vs Actual Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_test = df_ols_t0.loc['2004':'2007'].iloc[:, 1:]\n",
    "\n",
    "plt.subplots(figsize=(12,12))\n",
    "plt.hist(m_ols.predict(X_test), bins=100, color='blue', alpha=0.5)\n",
    "plt.hist(y_test, bins=100, color='red', alpha=0.5)\n",
    "plt.title(\"Histogram of Fitted and Actual Energy\")\n",
    "plt.xlabel(\"Energy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend(['Fitted Values', 'Actual Values'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitted Values vs Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,12))\n",
    "plt.scatter(m_ols.predict(X_test), m_ols.resid, s=0.01, alpha=0.5)\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Relationship between Fitted Values and Residuals\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, _, f_value, f_pvalue = statsmodels.stats.diagnostic.het_breuschpagan(m_ols.resid, df_ols.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bp test f_value: ' + str(f_value))\n",
    "print('bp test f_pvalue: ' + str(f_pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the very low p-value indicates a very likely violation of homoscedasticity (constant variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,12))\n",
    "plt.hist(m_ols_filt.resid, bins=50)\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "statsmodels.stats.diagnostic.normal_ad(m_ols.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Anderson-Darling Normality test has the null hypothesis that the data is normally distributed. The p-value of the test statistic is very small, thus we reject the null hypothesis that the data is normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile-Quantile Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qqplot(m_ols.resid, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE training data m_ols_t0\n",
    "statsmodels.tools.eval_measures.meanabs(df_ols_fs.energy, m_ols_t0.fittedvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE training data m_ols\n",
    "statsmodels.tools.eval_measures.meanabs(df_ols_fs.energy, m_ols.fittedvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE training data m_ols_fs\n",
    "statsmodels.tools.eval_measures.meanabs(df_ols_fs.energy, m_ols_fs.fittedvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE training data m_ols_filt\n",
    "statsmodels.tools.eval_measures.meanabs(df_ols_filt.energy, m_ols_filt.fittedvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae / df_ols_filt.energy.mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
